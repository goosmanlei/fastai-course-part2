{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ ğŸ¤— Diffusers å®ç° Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pedro Cuenca, Patrick von Platen, Suraj Patil, Jeremy Howard**\n",
    "\n",
    "ä½ å¯èƒ½å·²ç»åœ¨ Twitterï¼ˆæˆ–å…¶ä»–åœ°æ–¹ï¼‰çœ‹åˆ°è¿‡å¾ˆå¤šé€šè¿‡è¾“å…¥ç®€çŸ­åœºæ™¯æè¿°å°±èƒ½ç”Ÿæˆå›¾åƒçš„ä¾‹å­ã€‚è¿™æ˜¯å¤šå¹´æ¥ç”Ÿæˆæ¨¡å‹ (Generative Model) ç ”ç©¶çš„æˆæœã€‚æœ¬ç¬”è®°æœ¬å°†ä»‹ç» Stable Diffusion â€”â€” ç›®å‰è´¨é‡æœ€é«˜çš„å¼€æºæ–‡ç”Ÿå›¾æ¨¡å‹ã€‚å®ƒè¶³å¤Ÿå°å·§ï¼Œå¯ä»¥åœ¨æ¶ˆè´¹çº§ GPU ä¸Šè¿è¡Œï¼Œè€Œä¸éœ€è¦æ•°æ®ä¸­å¿ƒçº§åˆ«çš„ç®—åŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨ ğŸ¤— Hugging Face çš„ [ğŸ§¨ Diffusers åº“](https://github.com/huggingface/diffusers)ï¼Œè¿™æ˜¯ç›®å‰æˆ‘ä»¬æ¨èç”¨äºæ‰©æ•£æ¨¡å‹ (Diffusion Model) çš„åº“ã€‚\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¼šçœ‹åˆ°ï¼Œç†è§£æœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹éœ€è¦æ·±å…¥ç†è§£ç°ä»£æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„è®¸å¤šåŸºç¡€æ¨¡å—ã€‚æœ¬ç¬”è®°æœ¬å°†å±•ç¤º Stable Diffusion çš„èƒ½åŠ›ï¼Œå¹¶ç®€è¦ä»‹ç»å…¶ä¸»è¦ç»„ä»¶ã€‚\n",
    "\n",
    "_å¦‚æœä½ åœ¨ Colab ä¸­æ‰“å¼€æœ¬ç¬”è®°æœ¬ï¼Œæˆ–è€…åœ¨ç”Ÿæˆç¬¬ä¸€å¼ å›¾ç‰‡æ—¶é‡åˆ°ç±»å‹é”™è¯¯ï¼Œè¯·å–æ¶ˆæ³¨é‡Šå¹¶è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼ã€‚_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq diffusers transformers fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦åœ¨ä½ çš„ç”µè„‘ä¸Šè¿è¡Œ Stable Diffusionï¼Œä½ éœ€è¦æ¥å—æ¨¡å‹è®¸å¯åè®®ã€‚è¿™æ˜¯ä¸€ä¸ªå¼€æ”¾çš„ CreativeML OpenRail-M è®¸å¯è¯ï¼Œå®ƒä¸å¯¹ä½ ç”Ÿæˆçš„è¾“å‡ºä¸»å¼ ä»»ä½•æƒåˆ©ï¼Œä½†ç¦æ­¢ä½ æ•…æ„ç”Ÿæˆéæ³•æˆ–æœ‰å®³å†…å®¹ã€‚[æ¨¡å‹å¡ç‰‡](https://huggingface.co/CompVis/stable-diffusion-v1-4) æä¾›äº†æ›´å¤šè¯¦æƒ…ã€‚å¦‚æœä½ æ¥å—è¯¥è®¸å¯è¯ï¼Œä½ éœ€è¦æˆä¸º ğŸ¤— Hugging Face Hub çš„æ³¨å†Œç”¨æˆ·ï¼Œå¹¶ä½¿ç”¨è®¿é—®ä»¤ç‰Œ (Access Token) æ‰èƒ½è¿è¡Œä»£ç ã€‚ä½ æœ‰ä¸¤ç§æ–¹å¼æä¾›è®¿é—®ä»¤ç‰Œï¼š\n",
    "\n",
    "* åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ `huggingface-cli login` å‘½ä»¤è¡Œå·¥å…·ï¼Œå¹¶åœ¨æç¤ºæ—¶ç²˜è´´ä½ çš„ä»¤ç‰Œã€‚ä»¤ç‰Œä¼šä¿å­˜åœ¨ä½ ç”µè„‘ä¸Šçš„æ–‡ä»¶ä¸­ã€‚\n",
    "* æˆ–è€…åœ¨ç¬”è®°æœ¬ä¸­ä½¿ç”¨ `notebook_login()`ï¼ŒåŠŸèƒ½ç›¸åŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from fastcore.all import concat\n",
    "from huggingface_hub import notebook_login\n",
    "from PIL import Image\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if not (Path.home()/'.cache/huggingface'/'token').exists(): notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion æµæ°´çº¿ (Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`StableDiffusionPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline) æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„[æ‰©æ•£æ¨ç†æµæ°´çº¿](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion)ï¼Œåªéœ€å‡ è¡Œä»£ç å°±èƒ½å¼€å§‹ç”Ÿæˆå›¾åƒã€‚è®¸å¤š Hugging Face åº“ï¼ˆä»¥åŠå…¶ä»–åº“å¦‚ scikit-learnï¼‰éƒ½ä½¿ç”¨\"æµæ°´çº¿\"(Pipeline) çš„æ¦‚å¿µæ¥è¡¨ç¤ºä¸€ç³»åˆ—ç»„åˆåœ¨ä¸€èµ·å®ŒæˆæŸé¡¹ä»»åŠ¡çš„æ­¥éª¤ã€‚æˆ‘ä»¬ç¨åä¼šè¯¦ç»†äº†è§£æµæ°´çº¿çš„å„ä¸ªæ­¥éª¤ - ç°åœ¨ï¼Œè®©æˆ‘ä»¬å…ˆç”¨å®ƒæ¥çœ‹çœ‹å®ƒèƒ½åšä»€ä¹ˆã€‚\n",
    "\n",
    "å½“æˆ‘ä»¬è¯´\"æ¨ç†\" (Inference) æ—¶ï¼ŒæŒ‡çš„æ˜¯ä½¿ç”¨ç°æœ‰æ¨¡å‹ç”Ÿæˆæ ·æœ¬ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯å›¾åƒï¼‰ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ–°æ•°æ®\"è®­ç»ƒ\" (Training) æˆ–å¾®è°ƒ (Fine-tuning) æ¨¡å‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ [`from_pretrained`](https://huggingface.co/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained) æ¥åˆ›å»ºæµæ°´çº¿å¹¶ä¸‹è½½é¢„è®­ç»ƒæƒé‡ã€‚æˆ‘ä»¬æŒ‡å®šä½¿ç”¨ `fp16`ï¼ˆåŠç²¾åº¦ï¼‰ç‰ˆæœ¬çš„æƒé‡ï¼Œå¹¶å‘Šè¯‰ `diffusers` æœŸæœ›è¯¥æ ¼å¼çš„æƒé‡ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»¥æ›´å¿«çš„é€Ÿåº¦è¿›è¡Œæ¨ç†ï¼Œè€Œè´¨é‡å‡ ä¹æ²¡æœ‰æ˜æ˜¾å·®å¼‚ã€‚ä¼ é€’ç»™ `from_pretrained` çš„å­—ç¬¦ä¸²ï¼ˆæœ¬ä¾‹ä¸­ä¸º `CompVis/stable-diffusion-v1-4`ï¼‰æ˜¯æ‰˜ç®¡åœ¨ [Hugging Face Hub](https://huggingface.co/models) ä¸Šçš„é¢„è®­ç»ƒæµæ°´çº¿çš„ä»“åº“ IDï¼›å®ƒä¹Ÿå¯ä»¥æ˜¯åŒ…å«æµæ°´çº¿æƒé‡çš„æœ¬åœ°ç›®å½•è·¯å¾„ã€‚é¦–æ¬¡è¿è¡Œæ­¤å•å…ƒæ ¼æ—¶ï¼Œæµæ°´çº¿ä¸­æ‰€æœ‰æ¨¡å‹çš„æƒé‡å°†è¢«ä¸‹è½½å¹¶ç¼“å­˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", variant=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æƒé‡é»˜è®¤ç¼“å­˜åœ¨ä½ çš„ä¸»ç›®å½•ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½ä½¿ç”¨æµæ°´çº¿æ¥å¼€å§‹åˆ›å»ºå›¾åƒäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœä½ çš„ GPU å†…å­˜ä¸è¶³ä»¥ä½¿ç”¨ `pipe`ï¼Œè¯·è¿è¡Œ `pipe.enable_attention_slicing()`\n",
    "\n",
    "å¦‚æ–‡æ¡£æ‰€è¿°ï¼š\n",
    "> å¯ç”¨æ­¤é€‰é¡¹åï¼Œæ³¨æ„åŠ›æ¨¡å—ä¼šå°†è¾“å…¥å¼ é‡åˆ‡ç‰‡ï¼Œåˆ†å¤šä¸ªæ­¥éª¤è®¡ç®—æ³¨æ„åŠ›ã€‚è¿™æœ‰åŠ©äºèŠ‚çœä¸€äº›å†…å­˜ï¼Œä½†ä¼šç•¥å¾®é™ä½é€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1024)\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ ä¼šæ³¨æ„åˆ°è¿è¡Œæµæ°´çº¿æ—¶ä¼šæ˜¾ç¤ºä¸€ä¸ªå¸¦æœ‰ä¸€å®šæ­¥æ•°çš„è¿›åº¦æ¡ã€‚è¿™æ˜¯å› ä¸º Stable Diffusion åŸºäºä¸€ç§æ¸è¿›å¼å»å™ªç®—æ³•ï¼Œèƒ½å¤Ÿä»çº¯éšæœºå™ªå£°å¼€å§‹åˆ›å»ºå‡ºé€¼çœŸçš„å›¾åƒã€‚è¿™ç±»æ¨¡å‹è¢«ç§°ä¸º _æ‰©æ•£æ¨¡å‹ (Diffusion Model)_ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªæ¨¡å‹ç»˜åˆ¶æ‰‹å†™æ•°å­—çš„è¿‡ç¨‹ç¤ºä¾‹ï¼ˆä»é¡¶éƒ¨çš„éšæœºå™ªå£°åˆ°åº•éƒ¨é€æ¸æ”¹è¿›çš„å›¾åƒï¼‰ï¼Œæˆ‘ä»¬å°†åœ¨è¯¾ç¨‹åé¢ä»é›¶å¼€å§‹æ„å»ºè¿™æ ·çš„æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1024)\n",
    "pipe(prompt, num_inference_steps=3).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1024)\n",
    "pipe(prompt, num_inference_steps=16).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼ (Classifier-Free Guidance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    w,h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    for i, img in enumerate(imgs): grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼ (Classifier-Free Guidance)_ æ˜¯ä¸€ç§å¢å¼ºè¾“å‡ºä¸æˆ‘ä»¬ä½¿ç”¨çš„æ¡ä»¶ä¿¡å·ï¼ˆæ–‡æœ¬ï¼‰ä¸€è‡´æ€§çš„æ–¹æ³•ã€‚\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œå¼•å¯¼å€¼è¶Šå¤§ï¼Œæ¨¡å‹è¶ŠåŠªåŠ›åœ°å»è¡¨ç°æ–‡æœ¬æç¤ºè¯ã€‚ä½†æ˜¯ï¼Œè¾ƒå¤§çš„å€¼å¾€å¾€ä¼šäº§ç”Ÿè¾ƒå°‘çš„å¤šæ ·æ€§ã€‚é»˜è®¤å€¼æ˜¯ `7.5`ï¼Œå®ƒä»£è¡¨äº†å¤šæ ·æ€§å’Œä¿çœŸåº¦ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚è¿™ç¯‡[åšå®¢æ–‡ç« ](https://benanne.github.io/2022/05/26/guidance.html)æ›´æ·±å…¥åœ°ä»‹ç»äº†å…¶å·¥ä½œåŸç†ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°ä¼ é€’ä¸€ä¸ªæç¤ºè¯åˆ—è¡¨è€Œä¸æ˜¯å­—ç¬¦ä¸²æ¥ä¸ºåŒä¸€ä¸ªæç¤ºè¯ç”Ÿæˆå¤šå¼ å›¾åƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows,num_cols = 4,4\n",
    "prompts = [prompt] * num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = concat(pipe(prompts, guidance_scale=g).images for g in [1.1,3,7,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(images, rows=num_rows, cols=num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è´Ÿé¢æç¤ºè¯ (Negative Prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_è´Ÿé¢æç¤ºè¯ (Negative Prompting)_ æŒ‡çš„æ˜¯ä½¿ç”¨å¦ä¸€ä¸ªæç¤ºè¯ï¼ˆè€Œä¸æ˜¯å®Œå…¨æ— æ¡ä»¶çš„ç”Ÿæˆï¼‰ï¼Œå¹¶ç¼©æ”¾è¯¥æç¤ºè¯ç”Ÿæˆç»“æœä¸æ¡ä»¶ç”Ÿæˆç»“æœä¹‹é—´çš„å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "prompt = \"Labrador in the style of Vermeer\"\n",
    "pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "pipe(prompt, negative_prompt=\"blue\").images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€šè¿‡ä½¿ç”¨è´Ÿé¢æç¤ºè¯ï¼Œæˆ‘ä»¬æ›´å¤šåœ°æœç€æ­£é¢æç¤ºè¯çš„æ–¹å‘ç§»åŠ¨ï¼Œæœ‰æ•ˆåœ°é™ä½äº†è´Ÿé¢æç¤ºè¯åœ¨æˆ‘ä»¬æ„å›¾ä¸­çš„é‡è¦æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å›¾ç”Ÿå›¾ (Image to Image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è™½ç„¶ Stable Diffusion æ˜¯ä¸ºç”Ÿæˆå›¾åƒè€Œè®­ç»ƒçš„ï¼Œå¹¶ä¸”å¯ä»¥é€‰æ‹©æ€§åœ°ä½¿ç”¨æ–‡æœ¬æ¡ä»¶æ¥å¼•å¯¼ç”Ÿæˆï¼Œä½†æˆ‘ä»¬å¯ä»¥å°†åŸå§‹çš„å›¾åƒæ‰©æ•£è¿‡ç¨‹ç”¨äºå…¶ä»–ä»»åŠ¡ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ä»çº¯å™ªå£°å¼€å§‹ï¼Œè€Œæ˜¯ä»ä¸€å¼ å›¾åƒå¼€å§‹ï¼Œå¹¶å‘å…¶æ·»åŠ ä¸€å®šé‡çš„å™ªå£°ã€‚æˆ‘ä»¬æ›¿æ¢å»å™ªè¿‡ç¨‹çš„åˆå§‹æ­¥éª¤ï¼Œå‡è£…æˆ‘ä»¬çš„å›¾åƒæ˜¯ç®—æ³•ç”Ÿæˆçš„ã€‚ç„¶åæˆ‘ä»¬åƒå¾€å¸¸ä¸€æ ·ä»é‚£ä¸ªçŠ¶æ€ç»§ç»­æ‰©æ•£è¿‡ç¨‹ã€‚\n",
    "\n",
    "è¿™é€šå¸¸ä¼šä¿ç•™æ„å›¾ï¼Œå°½ç®¡ç»†èŠ‚å¯èƒ½ä¼šå‘ç”Ÿå¾ˆå¤§å˜åŒ–ã€‚è¿™å¯¹äºè‰å›¾æ¥è¯´éå¸¸æ£’ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™äº›æ“ä½œï¼ˆæä¾›åˆå§‹å›¾åƒã€å‘å…¶æ·»åŠ ä¸€äº›å™ªå£°å¹¶ä»é‚£é‡Œè¿è¡Œæ‰©æ•£ï¼‰å¯ä»¥ç”±ä¸€ä¸ªä¸“é—¨çš„å›¾ç”Ÿå›¾æµæ°´çº¿è‡ªåŠ¨æ‰§è¡Œï¼š`StableDiffusionImg2ImgPipeline`ã€‚è¿™æ˜¯å…¶ [`__call__` æ–¹æ³•](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py#L124) çš„æºä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from fastdownload import FastDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    variant=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ç”± [ç”¨æˆ· VigilanteRogue81](https://huggingface.co/spaces/huggingface-projects/diffuse-the-rest/discussions/204) åˆ›å»ºçš„è‰å›¾ä½œä¸ºç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = FastDownload().download('https://cdn-uploads.huggingface.co/production/uploads/1664665907257-noauth.png')\n",
    "init_image = Image.open(p).convert(\"RGB\")\n",
    "init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "prompt = \"Wolf howling at the moon, photorealistic 4K\"\n",
    "images = pipe(prompt=prompt, num_images_per_prompt=3, image=init_image, strength=0.8, num_inference_steps=50).images\n",
    "image_grid(images, rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå–œæ¬¢çš„æ„å›¾åï¼Œå¯ä»¥å°†å®ƒç”¨ä½œä¸‹ä¸€ä¸ªæç¤ºè¯çš„ç§å­ï¼Œè¿›ä¸€æ­¥æ”¹å˜ç»“æœã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢çš„ç¬¬ä¸‰å¼ å›¾åƒï¼Œå°è¯•ç”¨å®ƒç”Ÿæˆæ¢µé«˜é£æ ¼çš„ä½œå“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "prompt = \"Oil painting of wolf howling at the moon by Van Gogh\"\n",
    "images = pipe(prompt=prompt, num_images_per_prompt=3, image=init_image, strength=1, num_inference_steps=70).images\n",
    "image_grid(images, rows=1, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ‰åˆ›é€ åŠ›çš„äººä½¿ç”¨ä¸åŒçš„å·¥å…·è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œä»¥å®ç°ä»–ä»¬è„‘æµ·ä¸­çš„æƒ³æ³•ã€‚è¿™é‡Œæœ‰ä¸€ä¸ª[å·¥å…·å»ºè®®åˆ—è¡¨](https://github.com/fastai/diffusion-nbs/blob/43a090286e5742f807d4ff58524c02a1888b3004/suggested_tools.md)å¯ä»¥å¸®åŠ©ä½ å…¥é—¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¾®è°ƒ (Fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[æˆ‘ä»¬å¦‚ä½•åœ¨ Lambda åˆ¶ä½œæ–‡æœ¬ç”Ÿæˆå®å¯æ¢¦æ¨¡å‹](https://lambdalabs.com/blog/how-to-fine-tune-stable-diffusion-how-we-made-the-text-to-pokemon-model-at-lambda/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lambdalabs.com/hs-fs/hubfs/2.%20Images/Images%20-%20Blog%20Posts/2022%20-%20Blog%20Images/image--3-.png?width=1152&height=768&name=image--3-.png)\n",
    "\n",
    "æˆ´çç è€³ç¯çš„å°‘å¥³ã€å¯çˆ±çš„å¥¥å·´é©¬ç”Ÿç‰©ã€å”çº³å¾·Â·ç‰¹æœ—æ™®ã€é²é‡Œæ–¯Â·çº¦ç¿°é€Šã€é¾™çŒ«ã€Hello Kitty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ–‡æœ¬åæ¼” (Textual Inversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡æœ¬åæ¼” (Textual Inversion) æ˜¯ä¸€ç§å¯ä»¥å¿«é€Ÿ\"æ•™ä¼š\"æ–‡æœ¬æ¨¡å‹ä¸€ä¸ªæ–°è¯ï¼Œå¹¶è®­ç»ƒå…¶åµŒå…¥å‘é‡æ¥è¿‘æŸç§è§†è§‰è¡¨ç¤ºçš„è¿‡ç¨‹ã€‚è¿™æ˜¯é€šè¿‡å‘è¯æ±‡è¡¨æ·»åŠ ä¸€ä¸ªæ–° tokenï¼Œå†»ç»“æ‰€æœ‰æ¨¡å‹çš„æƒé‡ï¼ˆæ–‡æœ¬ç¼–ç å™¨é™¤å¤–ï¼‰ï¼Œç„¶åç”¨å‡ å¼ ä»£è¡¨æ€§å›¾åƒè¿›è¡Œè®­ç»ƒæ¥å®ç°çš„ã€‚\n",
    "\n",
    "è¿™æ˜¯[è®ºæ–‡ä½œè€…](https://textual-inversion.github.io)å¯¹è¯¥è¿‡ç¨‹çš„ç¤ºæ„å›¾ã€‚\n",
    "\n",
    "![Textual Inversion ç¤ºæ„å›¾](https://textual-inversion.github.io/static/images/training/training.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ å¯ä»¥ä½¿ç”¨ä½ æä¾›çš„ç…§ç‰‡é€šè¿‡[è¿™ä¸ªè®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)æˆ– [Google Colab ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb)è®­ç»ƒä½ è‡ªå·±çš„ tokenã€‚è¿˜æœ‰ä¸€ä¸ª[ç”¨äºæ¨ç†çš„ Colab ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_conceptualizer_inference.ipynb)ï¼Œä½†æˆ‘ä»¬å°†åœ¨ä¸‹é¢å±•ç¤ºå°†è®­ç»ƒå¥½çš„ token æ·»åŠ åˆ°è¯æ±‡è¡¨å¹¶ä½¿å…¶ä¸é¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹ä¸€èµ·å·¥ä½œæ‰€éœ€éµå¾ªçš„æ­¥éª¤ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ä¸º[è¿™ç§é£æ ¼](https://huggingface.co/sd-concepts-library/indian-watercolor-portraits)è®­ç»ƒçš„åµŒå…¥æ¥å°è¯•ä¸€ä¸ªç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", variant=\"fp16\", torch_dtype=torch.float16) \n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_url = \"https://huggingface.co/sd-concepts-library/indian-watercolor-portraits/resolve/main/learned_embeds.bin\"\n",
    "embeds_path = FastDownload().download(embeds_url)\n",
    "embeds_dict = torch.load(str(embeds_path), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–° token çš„åµŒå…¥å‘é‡å­˜å‚¨åœ¨ä¸€ä¸ªå°å‹ PyTorch åºåˆ—åŒ–å­—å…¸ä¸­ï¼Œå…¶é”®æ˜¯è®­ç»ƒçš„æ–°æ–‡æœ¬ tokenã€‚ç”±äºæˆ‘ä»¬æµæ°´çº¿çš„ç¼–ç å™¨ä¸çŸ¥é“è¿™ä¸ªè¯ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æ·»åŠ å®ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "new_token, embeds = next(iter(embeds_dict.items()))\n",
    "embeds = embeds.to(text_encoder.dtype)\n",
    "new_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å°†æ–° token æ·»åŠ åˆ°åˆ†è¯å™¨ (tokenizer)ï¼Œå¹¶å°†è®­ç»ƒå¥½çš„åµŒå…¥å‘é‡æ·»åŠ åˆ°åµŒå…¥è¡¨ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokenizer.add_tokens(new_token) == 1, \"The token already exists!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "new_token_id = tokenizer.convert_tokens_to_ids(new_token)\n",
    "text_encoder.get_input_embeddings().weight.data[new_token_id] = embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿è¡Œæ¨ç†ï¼Œå¹¶åƒå¼•ç”¨å­—å…¸ä¸­çš„å¦ä¸€ä¸ªå•è¯ä¸€æ ·å¼•ç”¨è¿™ä¸ªé£æ ¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "image = pipe(\"Woman reading in the style of <watercolor-portrait>\").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dreambooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dreambooth](https://dreambooth.github.io) æ˜¯ä¸€ç§å¾®è°ƒæ–¹æ³•ï¼Œå®ƒè¯•å›¾é€šè¿‡åªæä¾›å°‘é‡æ–°ä¸»é¢˜çš„å›¾åƒæ¥å¼•å…¥æ–°ä¸»é¢˜ã€‚å…¶ç›®æ ‡ä¸[æ–‡æœ¬åæ¼”](#æ–‡æœ¬åæ¼”-textual-inversion)ç±»ä¼¼ï¼Œä½†è¿‡ç¨‹ä¸åŒã€‚Dreambooth ä¸åƒæ–‡æœ¬åæ¼”é‚£æ ·åˆ›å»ºä¸€ä¸ªæ–° tokenï¼Œè€Œæ˜¯é€‰æ‹©è¯æ±‡è¡¨ä¸­ä¸€ä¸ªç°æœ‰çš„ tokenï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªå¾ˆå°‘ä½¿ç”¨çš„ï¼‰ï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œå‡ ç™¾æ­¥çš„å¾®è°ƒï¼Œä½¿è¯¥ token æ¥è¿‘æˆ‘ä»¬æä¾›çš„å›¾åƒã€‚è¿™æ˜¯ä¸€ä¸ªå¸¸è§„çš„å¾®è°ƒè¿‡ç¨‹ï¼Œå…¶ä¸­æ‰€æœ‰æ¨¡å—éƒ½è¢«è§£å†»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨ç±»ä¼¼ `\"photo of a sks person\"` çš„æç¤ºè¯å¾®è°ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œä½¿ç”¨ç½•è§çš„ `sks` token æ¥é™å®š `person` è¿™ä¸ªè¯ï¼Œå¹¶ä½¿ç”¨ Jeremy çš„ç…§ç‰‡ä½œä¸ºç›®æ ‡ã€‚è®©æˆ‘ä»¬çœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"pcuenq/jh_dreambooth_1000\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1000)\n",
    "\n",
    "prompt = \"Painting of sks person in the style of Paul Signac\"\n",
    "images = pipe(prompt, num_images_per_prompt=4).images\n",
    "image_grid(images, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ Dreambooth è¿›è¡Œå¾®è°ƒæ˜¯æ¯”è¾ƒæ£˜æ‰‹çš„ï¼Œå¯¹è¶…å‚æ•°å¾ˆæ•æ„Ÿï¼Œå› ä¸ºæˆ‘ä»¬æœ¬è´¨ä¸Šæ˜¯åœ¨è¦æ±‚æ¨¡å‹å¯¹æä¾›çš„å›¾åƒè¿‡æ‹Ÿåˆæç¤ºè¯ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šè§‚å¯Ÿåˆ°ä¸€äº›é—®é¢˜ï¼Œå¦‚ç›¸å…³æœ¯è¯­ï¼ˆæœ¬ä¾‹ä¸­çš„ `\"person\"`ï¼‰çš„ç¾éš¾æ€§é—å¿˜ã€‚ä½œè€…åº”ç”¨äº†ä¸€ç§å«åš\"å…ˆéªŒä¿æŒ\" (Prior Preservation) çš„æŠ€æœ¯æ¥å°è¯•é¿å…è¿™ç§æƒ…å†µï¼Œé€šè¿‡ä½¿ç”¨è¯¥æœ¯è¯­çš„å…¶ä»–ç¤ºä¾‹ï¼ˆé™¤äº†æˆ‘ä»¬æä¾›çš„é‚£äº›ï¼‰è¿›è¡Œç‰¹æ®Šæ­£åˆ™åŒ–ã€‚è¿™ä¸ªæƒ³æ³•çš„é…·ä¹‹å¤„åœ¨äºï¼Œè¿™äº›ç¤ºä¾‹å¯ä»¥ç”±é¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹æœ¬èº«è½»æ¾ç”Ÿæˆï¼æˆ‘ä»¬åœ¨ä¸ºä¸Šä¸€ä¸ªç¤ºä¾‹è®­ç»ƒçš„æ¨¡å‹ä¸­æ²¡æœ‰ä½¿ç”¨è¯¥æ–¹æ³•ã€‚\n",
    "\n",
    "å…¶ä»–å¯èƒ½æœ‰æ•ˆçš„æƒ³æ³•åŒ…æ‹¬ï¼šä½¿ç”¨ EMA ä½¿æœ€ç»ˆæƒé‡ä¿ç•™ä¸€äº›å…ˆå‰çš„çŸ¥è¯†ã€ä½¿ç”¨æ¸è¿›å¼å­¦ä¹ ç‡è¿›è¡Œå¾®è°ƒï¼Œæˆ–è€…å°†æ–‡æœ¬åæ¼”çš„ä¼˜ç‚¹ä¸ Dreambooth ç»“åˆèµ·æ¥ã€‚è¿™äº›éƒ½å¯ä»¥æˆä¸ºä¸€äº›æœ‰è¶£çš„é¡¹ç›®æ¥å°è¯•ï¼\n",
    "\n",
    "å¦‚æœä½ æƒ³è®­ç»ƒè‡ªå·±çš„ Dreambooth æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨[è¿™ä¸ªè„šæœ¬](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)æˆ–[è¿™ä¸ª Colab ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä»€ä¹ˆæ˜¯ Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ½œåœ¨æ‰©æ•£ (Latent Diffusion) æœ‰ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼š\n",
    "\n",
    "1. è‡ªç¼–ç å™¨ (Autoencoder)ï¼Œå³ VAE (å˜åˆ†è‡ªç¼–ç å™¨ï¼ŒVariational Autoencoder)ã€‚\n",
    "2. [U-Net](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb#scrollTo=wW8o1Wp0zRkq)ã€‚\n",
    "3. æ–‡æœ¬ç¼–ç å™¨ï¼Œä¾‹å¦‚ [CLIP çš„æ–‡æœ¬ç¼–ç å™¨](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)ã€‚\n",
    "\n",
    "U-Net çš„è¾“å‡ºæ˜¯å™ªå£°æ®‹å·®ï¼Œç”¨äºé€šè¿‡è°ƒåº¦å™¨ç®—æ³• (Scheduler Algorithm) è®¡ç®—å»å™ªåçš„æ½œåœ¨å›¾åƒè¡¨ç¤ºã€‚å¯ä»¥ä½¿ç”¨è®¸å¤šä¸åŒçš„è°ƒåº¦å™¨ç®—æ³•è¿›è¡Œæ­¤è®¡ç®—ï¼Œæ¯ç§ç®—æ³•éƒ½æœ‰å…¶ä¼˜ç¼ºç‚¹ã€‚å¯¹äº Stable Diffusionï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ä»¥ä¸‹ä¹‹ä¸€ï¼š\n",
    "\n",
    "- [PNDM è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py)ï¼ˆé»˜è®¤ä½¿ç”¨ï¼‰\n",
    "- [DDIM è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py)\n",
    "- [K-LMS è°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ½œå˜é‡å’Œå›è°ƒ (Latents and Callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable Diffusion åŸºäºä¸€ç§ç‰¹æ®Šç±»å‹çš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º**æ½œåœ¨æ‰©æ•£ (Latent Diffusion)**ï¼Œåœ¨è®ºæ–‡ [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) ä¸­æå‡ºã€‚\n",
    "\n",
    "é€šç”¨æ‰©æ•£æ¨¡å‹æ˜¯è¢«è®­ç»ƒæ¥é€æ­¥*å»å™ª*éšæœºé«˜æ–¯å™ªå£°çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œæœ€ç»ˆå¾—åˆ°æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ ·æœ¬ï¼Œä¾‹å¦‚*å›¾åƒ*ã€‚æœ‰å…³å…¶å·¥ä½œåŸç†çš„æ›´è¯¦ç»†æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹[è¿™ä¸ª Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)ã€‚\n",
    "\n",
    "æ‰©æ•£æ¨¡å‹å·²è¢«è¯æ˜åœ¨ç”Ÿæˆå›¾åƒæ•°æ®æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ä½†æ‰©æ•£æ¨¡å‹çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯åå‘å»å™ªè¿‡ç¨‹å¾ˆæ…¢ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹æ¶ˆè€—å¤§é‡å†…å­˜ï¼Œå› ä¸ºå®ƒä»¬åœ¨åƒç´ ç©ºé—´ (Pixel Space) ä¸­æ“ä½œï¼Œå½“ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼Œè¿™å˜å¾—éå¸¸æ˜‚è´µã€‚å› æ­¤ï¼Œè®­ç»ƒè¿™äº›æ¨¡å‹ä»¥åŠå°†å®ƒä»¬ç”¨äºæ¨ç†éƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚\n",
    "\n",
    "æ½œåœ¨æ‰©æ•£å¯ä»¥é€šè¿‡åœ¨è¾ƒä½ç»´åº¦çš„ _æ½œç©ºé—´ (Latent Space)_ ä¸Šåº”ç”¨æ‰©æ•£è¿‡ç¨‹æ¥å‡å°‘å†…å­˜å’Œè®¡ç®—å¤æ‚åº¦ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å®é™…çš„åƒç´ ç©ºé—´ã€‚è¿™æ˜¯æ ‡å‡†æ‰©æ•£å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ä¹‹é—´çš„å…³é”®åŒºåˆ«ï¼š**åœ¨æ½œåœ¨æ‰©æ•£ä¸­ï¼Œæ¨¡å‹è¢«è®­ç»ƒæ¥ç”Ÿæˆå›¾åƒçš„æ½œåœ¨ï¼ˆå‹ç¼©çš„ï¼‰è¡¨ç¤ºã€‚**\n",
    "\n",
    "Stable Diffusion æµæ°´çº¿å¯ä»¥å°†ä¸­é—´æ½œå˜é‡å‘é€åˆ°æˆ‘ä»¬æä¾›çš„å›è°ƒå‡½æ•°ã€‚é€šè¿‡å°†è¿™äº›æ½œå˜é‡é€šè¿‡å›¾åƒè§£ç å™¨ï¼ˆæµæ°´çº¿çš„ `vae` ç»„ä»¶ï¼‰è¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å»å™ªè¿‡ç¨‹å¦‚ä½•è¿›è¡Œä»¥åŠå›¾åƒå¦‚ä½•é€æ¸å±•å¼€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = pipe.vae\n",
    "images = []\n",
    "\n",
    "def latents_callback(i, t, latents):\n",
    "    latents = 1 / 0.18215 * latents\n",
    "    image = vae.decode(latents).sample[0]\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.cpu().permute(1, 2, 0).numpy()\n",
    "    images.extend(pipe.numpy_to_pil(image))\n",
    "\n",
    "prompt = \"Portrait painting of Jeremy Howard looking happy.\"\n",
    "torch.manual_seed(9000)\n",
    "final_image = pipe(prompt, callback=latents_callback, callback_steps=12).images[0]\n",
    "images.append(final_image)\n",
    "image_grid(images, rows=1, cols=len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä¸ºä»€ä¹ˆæ½œåœ¨æ‰©æ•£æ—¢å¿«é€Ÿåˆé«˜æ•ˆï¼Ÿ**\n",
    "\n",
    "ç”±äºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ U-Net åœ¨ä½ç»´ç©ºé—´ä¸Šæ“ä½œï¼Œä¸åƒç´ ç©ºé—´æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼Œå®ƒå¤§å¤§å‡å°‘äº†å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚ä¾‹å¦‚ï¼ŒStable Diffusion ä¸­ä½¿ç”¨çš„è‡ªç¼–ç å™¨çš„ç¼©å‡å› å­ä¸º 8ï¼Œä½†ä½¿ç”¨ 4 ä¸ªé€šé“è€Œä¸æ˜¯ 3 ä¸ªã€‚è¿™æ„å‘³ç€å½¢çŠ¶ä¸º `(3, 512, 512)` çš„å›¾åƒåœ¨æ½œç©ºé—´ä¸­å˜ä¸º `(4, 64, 64)`ï¼Œè¿™éœ€è¦çš„å†…å­˜å‡å°‘äº† `8 Ã— 8 Ã— 3/4 = 48` å€ã€‚\n",
    "\n",
    "è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿åœ¨ 16GB çš„ Colab GPU ä¸Šä¹Ÿèƒ½å¦‚æ­¤å¿«é€Ÿåœ°ç”Ÿæˆ `512 Ã— 512` å›¾åƒçš„åŸå› ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ·±å…¥æµæ°´çº¿å†…éƒ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¨ç†æµæ°´çº¿åªæ˜¯ä¸€å°æ®µä»£ç ï¼Œå°†å„ä¸ªç»„ä»¶è¿æ¥åœ¨ä¸€èµ·å¹¶æ‰§è¡Œæ¨ç†å¾ªç¯ã€‚[è¿™å°±æ˜¯å®ƒçš„å…¨éƒ¨å†…å®¹](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py#L204)ã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†é€æ­¥åŠ è½½å’Œè¿æ¥å„ä¸ªéƒ¨åˆ†ï¼Œçœ‹çœ‹æˆ‘ä»¬å¦‚ä½•è‡ªå·±ç¼–å†™å®ƒã€‚æˆ‘ä»¬å°†é¦–å…ˆä»é¢„è®­ç»ƒæƒé‡åŠ è½½æ‰€éœ€çš„æ‰€æœ‰æ¨¡å—ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ–‡æœ¬ç¼–ç å™¨å’Œåˆ†è¯å™¨ã€‚è¿™äº›æ¥è‡ªæ ‡å‡† CLIP æ¨¡å‹çš„æ–‡æœ¬éƒ¨åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨ OpenAI å‘å¸ƒçš„æƒé‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTextModel, CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16)\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥æˆ‘ä»¬åŠ è½½ `vae` å’Œ `unet`ã€‚è¿™äº›æ˜¯ç‹¬ç«‹çš„æ¨¡å‹ï¼Œå…¶æƒé‡å­˜å‚¨åœ¨ Stable Diffusion ä»“åº“çš„æ–‡ä»¶å¤¹ä¸­ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `subfolder` å‚æ•°æ¥å¼•ç”¨[è¿™äº›ä½ç½®](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸åŸå§‹ç‰ˆæœ¬ä¸åŒçš„ VAEï¼Œå®ƒç»è¿‡äº†æ›´å¤šæ­¥éª¤çš„å¾®è°ƒ\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ä½¿äº‹æƒ…æœ‰æ‰€ä¸åŒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¦ä¸€ä¸ªè°ƒåº¦å™¨ã€‚æ ‡å‡†æµæ°´çº¿ä½¿ç”¨ [PNDM è°ƒåº¦å™¨](https://arxiv.org/abs/2202.09778)ï¼Œä½†æˆ‘ä»¬å°†ä½¿ç”¨ [Katherine Crowson](https://github.com/crowsonkb) å‡ºè‰²çš„ K-LMS è°ƒåº¦å™¨ã€‚\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦å°å¿ƒä½¿ç”¨ä¸è®­ç»ƒæœŸé—´ç›¸åŒçš„å™ªå£°è®¡åˆ’ã€‚è¯¥è®¡åˆ’ç”±å™ªå£°æ­¥æ•°å’Œæ¯ä¸€æ­¥æ·»åŠ çš„å™ªå£°é‡å®šä¹‰ï¼Œè¿™æ˜¯ä» _beta_ å‚æ•°æ¨å¯¼å‡ºæ¥çš„ã€‚\n",
    "\n",
    "å¯¹äº K-LMS è°ƒåº¦å™¨ï¼Œä»¥ä¸‹æ˜¯è®­ç»ƒæœŸé—´ä½¿ç”¨çš„ 1000 æ­¥å™ªå£°è¿‡ç¨‹ä¸­ beta çš„æ¼”å˜ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_start,beta_end = 0.00085,0.012\n",
    "plt.plot(torch.linspace(beta_start**0.5, beta_end**0.5, 1000) ** 2)\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Î²');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import LMSDiscreteScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LMSDiscreteScheduler(beta_start=beta_start, beta_end=beta_end, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å®šä¹‰ç”¨äºç”Ÿæˆçš„å‚æ•°ã€‚\n",
    "\n",
    "ä¸ä¹‹å‰çš„ç¤ºä¾‹ä¸åŒï¼Œæˆ‘ä»¬å°† `num_inference_steps` è®¾ç½®ä¸º 70 ä»¥è·å¾—æ›´æ¸…æ™°çš„å›¾åƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "\n",
    "height = 512\n",
    "width = 512\n",
    "num_inference_steps = 70\n",
    "guidance_scale = 7.5\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯¹æç¤ºè¯è¿›è¡Œåˆ†è¯ã€‚æ¨¡å‹è¦æ±‚æ¯ä¸ªæç¤ºè¯å…·æœ‰ç›¸åŒæ•°é‡çš„ tokenï¼Œå› æ­¤ä½¿ç”¨å¡«å…… (Padding) æ¥ç¡®ä¿æˆ‘ä»¬è¾¾åˆ°æ‰€éœ€çš„é•¿åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "text_input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(49407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ³¨æ„åŠ›æ©ç  (Attention Mask) ä½¿ç”¨é›¶æ¥è¡¨ç¤ºæˆ‘ä»¬ä¸æ„Ÿå…´è¶£çš„ tokenã€‚è¿™äº›éƒ½æ˜¯å¡«å…… tokenã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–‡æœ¬ç¼–ç å™¨ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„æ–‡æœ¬æç¤ºè¯æä¾›åµŒå…¥å‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = text_encoder(text_input.input_ids.to(\"cuda\"))[0].half()\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬è¿˜è·å–æ‰§è¡Œæ— æ¡ä»¶ç”Ÿæˆæ‰€éœ€çš„åµŒå…¥å‘é‡ï¼Œè¿™æ˜¯é€šè¿‡ç©ºå­—ç¬¦ä¸²å®ç°çš„ï¼šæ¨¡å‹å¯ä»¥è‡ªç”±åœ°æœä»»ä½•æ–¹å‘å‘å±•ï¼Œåªè¦å®ƒäº§ç”Ÿçœ‹èµ·æ¥åˆç†çš„å›¾åƒã€‚è¿™äº›åµŒå…¥å‘é‡å°†ç”¨äºåº”ç”¨åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer(\n",
    "    [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    ")\n",
    "uncond_embeddings = text_encoder(uncond_input.input_ids.to(\"cuda\"))[0].half()\n",
    "uncond_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹äºåˆ†ç±»å™¨è‡ªç”±å¼•å¯¼ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œä¸¤æ¬¡å‰å‘ä¼ æ’­ã€‚ä¸€æ¬¡ä½¿ç”¨æ¡ä»¶è¾“å…¥ (`text_embeddings`)ï¼Œå¦ä¸€æ¬¡ä½¿ç”¨æ— æ¡ä»¶åµŒå…¥ (`uncond_embeddings`)ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…è¿æ¥æˆä¸€ä¸ªæ‰¹æ¬¡ï¼Œä»¥é¿å…è¿›è¡Œä¸¤æ¬¡å‰å‘ä¼ æ’­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¦å¼€å§‹å»å™ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬ä»çº¯é«˜æ–¯ï¼ˆæ­£æ€ï¼‰å™ªå£°å¼€å§‹ã€‚è¿™äº›æ˜¯æˆ‘ä»¬çš„åˆå§‹æ½œå˜é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "latents = torch.randn((batch_size, unet.in_channels, height // 8, width // 8))\n",
    "latents = latents.to(\"cuda\").half()\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4Ã—64Ã—64` æ˜¯è¾“å…¥å½¢çŠ¶ã€‚åœ¨å»å™ªè¿‡ç¨‹å®Œæˆåï¼Œè§£ç å™¨ç¨åä¼šå°†è¿™ä¸ªæ½œåœ¨è¡¨ç¤ºè½¬æ¢ä¸º `3Ã—512Ã—512` çš„å›¾åƒã€‚\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”¨é€‰æ‹©çš„ `num_inference_steps` åˆå§‹åŒ–è°ƒåº¦å™¨ã€‚è¿™å°†å‡†å¤‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ä½¿ç”¨çš„å†…éƒ¨çŠ¶æ€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.set_timesteps(num_inference_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬æŒ‰è°ƒåº¦å™¨è¦æ±‚çš„æ ‡å‡†å·®ç¼©æ”¾åˆå§‹å™ªå£°ã€‚è¿™ä¸ªå€¼å°†å–å†³äºæˆ‘ä»¬ä½¿ç”¨çš„ç‰¹å®šè°ƒåº¦å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = latents * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å‡†å¤‡å¥½ç¼–å†™å»å™ªå¾ªç¯äº†ã€‚æ—¶é—´æ­¥ä» `999` åˆ° `0`ï¼ˆè®­ç»ƒæœŸé—´ä½¿ç”¨çš„ 1000 æ­¥ï¼‰æŒ‰ç…§ç‰¹å®šçš„è®¡åˆ’è¿›è¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scheduler.timesteps, scheduler.sigmas[:-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(tqdm(scheduler.timesteps)):\n",
    "    input = torch.cat([latents] * 2)\n",
    "    input = scheduler.scale_model_input(input, t)\n",
    "\n",
    "    # é¢„æµ‹å™ªå£°æ®‹å·®\n",
    "    with torch.no_grad(): pred = unet(input, t, encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "    # æ‰§è¡Œå¼•å¯¼\n",
    "    pred_uncond, pred_text = pred.chunk(2)\n",
    "    pred = pred_uncond + guidance_scale * (pred_text - pred_uncond)\n",
    "\n",
    "    # è®¡ç®—\"å‰ä¸€ä¸ª\"å™ªå£°æ ·æœ¬\n",
    "    latents = scheduler.step(pred, t, latents).prev_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ä¸ªè¿‡ç¨‹å®Œæˆåï¼Œæˆ‘ä»¬çš„ `latents` åŒ…å«å›¾åƒçš„å»å™ªè¡¨ç¤ºã€‚æˆ‘ä»¬ä½¿ç”¨ `vae` è§£ç å™¨å°†å…¶è½¬æ¢å›åƒç´ ç©ºé—´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): image = vae.decode(1 / 0.18215 * latents).sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åï¼Œè®©æˆ‘ä»¬å°†å›¾åƒè½¬æ¢ä¸º PIL æ ¼å¼ä»¥ä¾¿æ˜¾ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = (image / 2 + 0.5).clamp(0, 1)\n",
    "image = image[0].detach().cpu().permute(1, 2, 0).numpy()\n",
    "image = (image * 255).round().astype(\"uint8\")\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä»…ä»£ç ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'a photograph of an astronaut riding a horse',\n",
    "    'an oil painting of an astronaut riding a horse in the style of grant wood'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tokenizer(prompts, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "text_embeddings = text_encoder(text_input.input_ids.to(\"cuda\"))[0].half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer([\"\"] * len(prompts), padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "uncond_embeddings = text_encoder(uncond_input.input_ids.to(\"cuda\"))[0].half()\n",
    "emb = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "g = guidance_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.randn((len(prompts), unet.in_channels, height//8, width//8))\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "latents = latents.to(\"cuda\").half() * scheduler.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ts in enumerate(tqdm(scheduler.timesteps)):\n",
    "    inp = scheduler.scale_model_input(torch.cat([latents] * 2), ts)\n",
    "    with torch.no_grad(): u,t = unet(inp, ts, encoder_hidden_states=emb).sample.chunk(2)\n",
    "    pred = u + g*(t-u)\n",
    "    latents = scheduler.step(pred, ts, latents).prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): image = vae.decode(1 / 0.18215 * latents).sample\n",
    "res = (image / 2 + 0.5).clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = res[0].detach().cpu().permute(1, 2, 0).numpy()\n",
    "image = (image * 255).round().astype(\"uint8\")\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = res[1].detach().cpu().permute(1, 2, 0).numpy()\n",
    "image = (image * 255).round().astype(\"uint8\")\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å°è£…æˆå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_enc(prompts, maxlen=None):\n",
    "    if maxlen is None: maxlen = tokenizer.model_max_length\n",
    "    inp = tokenizer(prompts, padding=\"max_length\", max_length=maxlen, truncation=True, return_tensors=\"pt\")\n",
    "    return text_encoder(inp.input_ids.to(\"cuda\"))[0].half()\n",
    "\n",
    "def mk_img(t):\n",
    "    image = (t/2+0.5).clamp(0,1).detach().cpu().permute(1, 2, 0).numpy()\n",
    "    return Image.fromarray((image*255).round().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_samples(prompts, g=7.5, seed=100, steps=70):\n",
    "    bs = len(prompts)\n",
    "    text = text_enc(prompts)\n",
    "    uncond = text_enc([\"\"] * bs, text.shape[1])\n",
    "    emb = torch.cat([uncond, text])\n",
    "    if seed: torch.manual_seed(seed)\n",
    "\n",
    "    latents = torch.randn((bs, unet.in_channels, height//8, width//8))\n",
    "    scheduler.set_timesteps(steps)\n",
    "    latents = latents.to(\"cuda\").half() * scheduler.init_noise_sigma\n",
    "\n",
    "    for i,ts in enumerate(tqdm(scheduler.timesteps)):\n",
    "        inp = scheduler.scale_model_input(torch.cat([latents] * 2), ts)\n",
    "        with torch.no_grad(): u,t = unet(inp, ts, encoder_hidden_states=emb).sample.chunk(2)\n",
    "        pred = u + g*(t-u)\n",
    "        latents = scheduler.step(pred, ts, latents).prev_sample\n",
    "\n",
    "    with torch.no_grad(): return vae.decode(1 / 0.18215 * latents).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mk_samples(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in images: display(mk_img(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
