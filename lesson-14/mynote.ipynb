{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Python Generator（生成器）实践指南\n",
    "\n",
    "Generator 是 Python 的内存高效迭代工具，使用 `yield` 关键字**惰性生成**数据，而非一次性加载到内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. 基础对比：列表 vs 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列表占用: 8250.7 KB\n",
      "生成器占用: 0.2 KB\n"
     ]
    }
   ],
   "source": [
    "# 列表：一次性生成所有数据，占用内存\n",
    "def squares_list(n):\n",
    "    return [i**2 for i in range(n)]\n",
    "\n",
    "# 生成器：按需生成，内存占用 O(1)\n",
    "def squares_gen(n):\n",
    "    for i in range(n):\n",
    "        yield i**2\n",
    "\n",
    "# 比较内存占用\n",
    "import sys\n",
    "n = 1_000_000\n",
    "print(f\"列表占用: {sys.getsizeof(squares_list(n)) / 1024:.1f} KB\")\n",
    "print(f\"生成器占用: {sys.getsizeof(squares_gen(n)) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. 生成器表达式（Generator Expression）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列表: [0, 1, 4, 9, 16]\n",
      "生成器对象: <generator object <genexpr> at 0x1065a1e50>\n",
      "逐个生成: [0, 1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "# 列表推导式\n",
    "squares_list = [x**2 for x in range(5)]\n",
    "print(f\"列表: {squares_list}\")  # [0, 1, 4, 9, 16]\n",
    "\n",
    "# 生成器表达式（用圆括号）\n",
    "squares_gen = (x**2 for x in range(5))\n",
    "print(f\"生成器对象: {squares_gen}\")  # <generator object>\n",
    "print(f\"逐个生成: {list(squares_gen)}\")  # [0, 1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. 实践案例：批量数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理批次: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "处理批次: [8, 9, 10, 11, 12, 13, 14, 15]\n",
      "处理批次: [16, 17, 18, 19, 20, 21, 22, 23]\n",
      "处理批次: [24]\n"
     ]
    }
   ],
   "source": [
    "def read_large_file(filepath):\n",
    "    \"\"\"逐行读取大文件（避免一次性加载）\"\"\"\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "\n",
    "def batch_generator(iterable, batch_size):\n",
    "    \"\"\"将数据流分批（类似 DataLoader）\"\"\"\n",
    "    batch = []\n",
    "    for item in iterable:\n",
    "        batch.append(item)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:  # 处理最后不满一批的数据\n",
    "        yield batch\n",
    "\n",
    "# 模拟大数据集处理\n",
    "data_stream = (x for x in range(25))  # 模拟 25 条数据\n",
    "for batch in batch_generator(data_stream, batch_size=8):\n",
    "    print(f\"处理批次: {batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. 高级技巧：双向通信（send & yield）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 10: 10.0\n",
      "输入 20: 15.0\n",
      "输入 30: 20.0\n"
     ]
    }
   ],
   "source": [
    "def running_average():\n",
    "    \"\"\"生成器计算滑动平均（接收外部输入）\"\"\"\n",
    "    total = 0\n",
    "    count = 0\n",
    "    avg = None\n",
    "    while True:\n",
    "        value = yield avg  # 返回当前平均值，接收新值\n",
    "        total += value\n",
    "        count += 1\n",
    "        avg = total / count\n",
    "\n",
    "# 使用示例\n",
    "avg_gen = running_average()\n",
    "next(avg_gen)  # 启动生成器\n",
    "print(f\"输入 10: {avg_gen.send(10)}\")  # 10.0\n",
    "print(f\"输入 20: {avg_gen.send(20)}\")  # 15.0\n",
    "print(f\"输入 30: {avg_gen.send(30)}\")  # 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. 核心要点总结\n",
    "\n",
    "| 特性 | 列表 | 生成器 |\n",
    "|------|------|--------|\n",
    "| **内存占用** | O(n) | O(1) |\n",
    "| **计算时机** | 立即全部计算 | 按需惰性计算 |\n",
    "| **可重复迭代** | ✅ 是 | ❌ 否（一次性消耗）|\n",
    "| **适用场景** | 小数据集、需多次访问 | 大数据流、管道处理 |\n",
    "\n",
    "**关键语法**：\n",
    "- `yield` — 暂停函数并返回值，下次从暂停处继续\n",
    "- `next(gen)` — 手动获取下一个值\n",
    "- `gen.send(value)` — 向生成器发送数据（双向通信）\n",
    "- `(expr for x in iterable)` — 生成器表达式（类似列表推导式）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fprs4ohbarl",
   "metadata": {},
   "source": [
    "# PyTorch 多进程并行（torch.multiprocessing）实践指南\n",
    "\n",
    "`torch.multiprocessing` 是 PyTorch 对 Python `multiprocessing` 的封装，提供了**跨进程共享 Tensor** 的能力。在数据加载（DataLoader）和分布式训练中广泛使用。\n",
    "\n",
    "**核心特性**：\n",
    "- 与 Python `multiprocessing` API 兼容\n",
    "- 支持 CUDA Tensor 跨进程共享（通过共享内存）\n",
    "- 提供 `spawn` 启动方式（避免 CUDA 上下文 fork 问题）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2nbuskgxki",
   "metadata": {},
   "source": [
    "## Task 1: 进程池基础 — 并行打印与进程标识\n",
    "\n",
    "**注意**：Jupyter notebook 无法直接运行 `multiprocessing`（序列化限制）。我们使用 `%%writefile` 创建 .py 脚本运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "xmy19evp8rt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing task1_multiprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile task1_multiprocessing.py\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "def worker_print(worker_id):\n",
    "    \"\"\"每个 worker 打印 1-5，并显示进程 PID\"\"\"\n",
    "    pid = os.getpid()\n",
    "    for i in range(1, 6):\n",
    "        print(f\"[Worker {worker_id}] PID={pid} | 计数={i}\")\n",
    "        time.sleep(0.1)  # 模拟耗时操作\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建并行度为 3 的进程池\n",
    "    num_workers = 3\n",
    "    processes = []\n",
    "    \n",
    "    print(f\"主进程 PID={os.getpid()}\\n\")\n",
    "    \n",
    "    # 启动 3 个子进程\n",
    "    for i in range(num_workers):\n",
    "        p = mp.Process(target=worker_print, args=(i,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    # 等待所有进程完成\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(\"\\n所有 worker 执行完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sb6zpnde3v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "主进程 PID=23520\n",
      "\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "[Worker 1] PID=23552 | 计数=1\n",
      "[Worker 2] PID=23553 | 计数=1\n",
      "[Worker 0] PID=23551 | 计数=1\n",
      "[Worker 0] PID=23551 | 计数=2[Worker 1] PID=23552 | 计数=2[Worker 2] PID=23553 | 计数=2\n",
      "\n",
      "\n",
      "[Worker 0] PID=23551 | 计数=3\n",
      "[Worker 1] PID=23552 | 计数=3\n",
      "[Worker 2] PID=23553 | 计数=3\n",
      "[Worker 0] PID=23551 | 计数=4\n",
      "[Worker 1] PID=23552 | 计数=4\n",
      "[Worker 2] PID=23553 | 计数=4\n",
      "[Worker 1] PID=23552 | 计数=5\n",
      "[Worker 0] PID=23551 | 计数=5\n",
      "[Worker 2] PID=23553 | 计数=5\n",
      "\n",
      "所有 worker 执行完毕！\n"
     ]
    }
   ],
   "source": [
    "# 运行 Task 1\n",
    "!python task1_multiprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wqytopvcd5",
   "metadata": {},
   "source": [
    "**关键要点**：\n",
    "- `mp.Process(target=func, args=())` — 创建子进程\n",
    "- `p.start()` — 启动进程（异步执行）\n",
    "- `p.join()` — 主进程等待子进程结束\n",
    "- `os.getpid()` — 获取当前进程 PID\n",
    "\n",
    "**Jupyter 限制说明**：\n",
    "- `multiprocessing` 使用 `pickle` 序列化函数传递给子进程\n",
    "- Jupyter notebook 中定义的函数无法被序列化（`__main__` 模块问题）\n",
    "- 解决方案：使用 `%%writefile` 创建独立 .py 文件，然后用 `!python` 运行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52vhxq6vp",
   "metadata": {},
   "source": [
    "## Task 2: 进程池通信 — 使用 Queue 传递计算结果\n",
    "\n",
    "同样使用 `%%writefile` 创建脚本，演示主进程与 worker 之间的双向通信。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8xoo6k7l4pb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task2_multiprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile task2_multiprocessing.py\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "def worker_compute(worker_id, task_queue, result_queue):\n",
    "    \"\"\"从任务队列获取数据，计算后将结果放入结果队列\"\"\"\n",
    "    pid = os.getpid()\n",
    "    print(f\"[Worker {worker_id}] PID={pid} 启动\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # 从任务队列获取任务（超时 1 秒）\n",
    "            task = task_queue.get(timeout=1)\n",
    "            if task is None:  # 收到结束信号\n",
    "                print(f\"[Worker {worker_id}] 收到结束信号，退出\")\n",
    "                break\n",
    "            \n",
    "            # 执行计算任务\n",
    "            x = task\n",
    "            result = x ** 2\n",
    "            time.sleep(0.2)  # 模拟耗时计算\n",
    "            \n",
    "            # 将结果放入结果队列\n",
    "            result_queue.put({\n",
    "                'worker_id': worker_id,\n",
    "                'pid': pid,\n",
    "                'input': x,\n",
    "                'output': result\n",
    "            })\n",
    "            print(f\"[Worker {worker_id}] 完成任务: {x}^2 = {result}\")\n",
    "            \n",
    "        except:\n",
    "            break  # 队列为空，退出\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建任务队列和结果队列\n",
    "    task_queue = mp.Queue()\n",
    "    result_queue = mp.Queue()\n",
    "    \n",
    "    # 准备 10 个任务\n",
    "    tasks = list(range(1, 11))\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    \n",
    "    # 启动 3 个 worker 进程\n",
    "    num_workers = 3\n",
    "    processes = []\n",
    "    \n",
    "    print(f\"主进程 PID={os.getpid()}\\n\")\n",
    "    \n",
    "    for i in range(num_workers):\n",
    "        p = mp.Process(target=worker_compute, args=(i, task_queue, result_queue))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    # 发送结束信号（每个 worker 一个 None）\n",
    "    for _ in range(num_workers):\n",
    "        task_queue.put(None)\n",
    "    \n",
    "    # 等待所有进程完成\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # 从结果队列收集所有结果\n",
    "    print(\"\\n主进程收集结果：\")\n",
    "    results = []\n",
    "    while not result_queue.empty():\n",
    "        result = result_queue.get()\n",
    "        results.append(result)\n",
    "        print(f\"  Worker {result['worker_id']} (PID={result['pid']}): \"\n",
    "              f\"{result['input']}^2 = {result['output']}\")\n",
    "    \n",
    "    print(f\"\\n共完成 {len(results)} 个任务\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行 Task 2\n",
    "!python task2_multiprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1180284",
   "metadata": {},
   "source": [
    "## Task 3: 流水线并行 — 专用收集 Worker 实现异步处理\n",
    "\n",
    "**改进点**：Task 2 中主进程需要等待所有计算完成才能收集结果。Task 3 创建专用的收集 worker，实现**计算与收集的流水线并行**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3tceqng1kuq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing task3_pipeline_multiprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile task3_pipeline_multiprocessing.py\n",
    "import torch.multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "def worker_compute(worker_id, task_queue, result_queue):\n",
    "    \"\"\"计算 worker：从任务队列获取任务，计算后发送到结果队列\"\"\"\n",
    "    pid = os.getpid()\n",
    "    print(f\"[计算Worker {worker_id}] PID={pid} 启动\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            task = task_queue.get(timeout=1)\n",
    "            if task is None:  # 收到结束信号\n",
    "                print(f\"[计算Worker {worker_id}] 收到结束信号，退出\")\n",
    "                break\n",
    "            \n",
    "            # 执行耗时计算\n",
    "            x = task\n",
    "            result = x ** 2\n",
    "            time.sleep(0.3)  # 模拟耗时计算\n",
    "            \n",
    "            # 立即将结果发送到结果队列（无需等待其他任务）\n",
    "            result_queue.put({\n",
    "                'worker_id': worker_id,\n",
    "                'pid': pid,\n",
    "                'input': x,\n",
    "                'output': result\n",
    "            })\n",
    "            print(f\"[计算Worker {worker_id}] 完成 {x}^2 = {result}，已发送到结果队列\")\n",
    "            \n",
    "        except:\n",
    "            break\n",
    "\n",
    "def worker_collect(result_queue, num_tasks):\n",
    "    \"\"\"\n",
    "    收集 worker：专门负责从结果队列收集结果并处理\n",
    "    \n",
    "    Args:\n",
    "        result_queue: 结果队列\n",
    "        num_tasks: 预期要收集的任务总数\n",
    "    \"\"\"\n",
    "    pid = os.getpid()\n",
    "    print(f\"[收集Worker] PID={pid} 启动，预期收集 {num_tasks} 个结果\\n\")\n",
    "    \n",
    "    collected = []\n",
    "    for i in range(num_tasks):\n",
    "        # 从结果队列获取结果（阻塞等待）\n",
    "        result = result_queue.get()\n",
    "        collected.append(result)\n",
    "        \n",
    "        # 实时处理结果（例如：保存、统计、可视化等）\n",
    "        print(f\"[收集Worker] 收到第 {i+1}/{num_tasks} 个结果: \"\n",
    "              f\"Worker{result['worker_id']} 计算 {result['input']}^2 = {result['output']}\")\n",
    "        time.sleep(0.1)  # 模拟结果处理耗时\n",
    "    \n",
    "    print(f\"\\n[收集Worker] 所有 {len(collected)} 个结果收集完毕！\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"汇总结果：\")\n",
    "    for r in collected:\n",
    "        print(f\"  {r['input']}^2 = {r['output']} (来自 Worker{r['worker_id']}, PID={r['pid']})\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建队列\n",
    "    task_queue = mp.Queue()\n",
    "    result_queue = mp.Queue()\n",
    "    \n",
    "    # 准备 10 个任务\n",
    "    tasks = list(range(1, 11))\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    \n",
    "    num_compute_workers = 3\n",
    "    num_tasks = len(tasks)\n",
    "    \n",
    "    print(f\"主进程 PID={os.getpid()}\")\n",
    "    print(f\"启动 {num_compute_workers} 个计算 worker + 1 个收集 worker\\n\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. 启动收集 worker（与计算 worker 并行运行）\n",
    "    collector = mp.Process(target=worker_collect, args=(result_queue, num_tasks))\n",
    "    collector.start()\n",
    "    \n",
    "    # 2. 启动计算 workers\n",
    "    compute_processes = []\n",
    "    for i in range(num_compute_workers):\n",
    "        p = mp.Process(target=worker_compute, args=(i, task_queue, result_queue))\n",
    "        p.start()\n",
    "        compute_processes.append(p)\n",
    "    \n",
    "    # 3. 发送结束信号给计算 workers\n",
    "    for _ in range(num_compute_workers):\n",
    "        task_queue.put(None)\n",
    "    \n",
    "    # 4. 等待所有进程完成\n",
    "    for p in compute_processes:\n",
    "        p.join()\n",
    "    print(\"\\n所有计算 worker 已退出\")\n",
    "    \n",
    "    collector.join()\n",
    "    print(\"收集 worker 已退出\")\n",
    "    \n",
    "    print(\"\\n主进程完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14l33d8bjzc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "主进程 PID=25553\n",
      "启动 3 个计算 worker + 1 个收集 worker\n",
      "\n",
      "==================================================\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/bytedance/venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "[计算Worker 0] PID=25561 启动\n",
      "[收集Worker] PID=25560 启动，预期收集 10 个结果\n",
      "\n",
      "[计算Worker 2] PID=25563 启动\n",
      "[计算Worker 1] PID=25562 启动\n",
      "[计算Worker 2] 完成 2^2 = 4，已发送到结果队列[计算Worker 0] 完成 1^2 = 1，已发送到结果队列\n",
      "\n",
      "[收集Worker] 收到第 1/10 个结果: Worker2 计算 2^2 = 4\n",
      "[计算Worker 1] 完成 3^2 = 9，已发送到结果队列\n",
      "[收集Worker] 收到第 2/10 个结果: Worker0 计算 1^2 = 1\n",
      "[收集Worker] 收到第 3/10 个结果: Worker1 计算 3^2 = 9\n",
      "[计算Worker 2] 完成 5^2 = 25，已发送到结果队列\n",
      "[计算Worker 1] 完成 6^2 = 36，已发送到结果队列\n",
      "[计算Worker 0] 完成 4^2 = 16，已发送到结果队列\n",
      "[收集Worker] 收到第 4/10 个结果: Worker2 计算 5^2 = 25\n",
      "[收集Worker] 收到第 5/10 个结果: Worker1 计算 6^2 = 36\n",
      "[收集Worker] 收到第 6/10 个结果: Worker0 计算 4^2 = 16\n",
      "[计算Worker 2] 完成 7^2 = 49，已发送到结果队列\n",
      "[计算Worker 1] 完成 8^2 = 64，已发送到结果队列[计算Worker 0] 完成 9^2 = 81，已发送到结果队列\n",
      "\n",
      "[计算Worker 1] 收到结束信号，退出\n",
      "[计算Worker 0] 收到结束信号，退出\n",
      "[收集Worker] 收到第 7/10 个结果: Worker2 计算 7^2 = 49\n",
      "[收集Worker] 收到第 8/10 个结果: Worker1 计算 8^2 = 64\n",
      "[收集Worker] 收到第 9/10 个结果: Worker0 计算 9^2 = 81\n",
      "[计算Worker 2] 完成 10^2 = 100，已发送到结果队列\n",
      "[计算Worker 2] 收到结束信号，退出\n",
      "[收集Worker] 收到第 10/10 个结果: Worker2 计算 10^2 = 100\n",
      "\n",
      "[收集Worker] 所有 10 个结果收集完毕！\n",
      "==================================================\n",
      "汇总结果：\n",
      "  2^2 = 4 (来自 Worker2, PID=25563)\n",
      "  1^2 = 1 (来自 Worker0, PID=25561)\n",
      "  3^2 = 9 (来自 Worker1, PID=25562)\n",
      "  5^2 = 25 (来自 Worker2, PID=25563)\n",
      "  6^2 = 36 (来自 Worker1, PID=25562)\n",
      "  4^2 = 16 (来自 Worker0, PID=25561)\n",
      "  7^2 = 49 (来自 Worker2, PID=25563)\n",
      "  8^2 = 64 (来自 Worker1, PID=25562)\n",
      "  9^2 = 81 (来自 Worker0, PID=25561)\n",
      "  10^2 = 100 (来自 Worker2, PID=25563)\n",
      "\n",
      "所有计算 worker 已退出\n",
      "收集 worker 已退出\n",
      "\n",
      "主进程完成！\n"
     ]
    }
   ],
   "source": [
    "# 运行 Task 3\n",
    "!python task3_pipeline_multiprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gdvsaowej7w",
   "metadata": {},
   "source": [
    "**Task 3 核心改进**：\n",
    "\n",
    "### 架构对比\n",
    "\n",
    "| 维度 | Task 2（主进程收集） | Task 3（专用 Worker 收集） |\n",
    "|------|---------------------|--------------------------|\n",
    "| **收集时机** | 等待所有计算完成后收集 | 边计算边收集（流水线） |\n",
    "| **并行度** | 计算阶段并行，收集串行 | 计算和收集完全并行 |\n",
    "| **响应速度** | 最后批量显示结果 | 实时显示每个结果 |\n",
    "| **适用场景** | 小任务量，快速计算 | 大任务量，长时间运行 |\n",
    "\n",
    "### 流水线优势\n",
    "\n",
    "```\n",
    "Task 2 时间线（串行收集）:\n",
    "[计算] ████████████ (所有任务完成)\n",
    "[收集]             ████ (批量收集)\n",
    "总耗时: 计算时间 + 收集时间\n",
    "\n",
    "Task 3 时间线（并行收集）:\n",
    "[计算] ████████████\n",
    "[收集] ████████████ (同时进行)\n",
    "总耗时: max(计算时间, 收集时间)\n",
    "```\n",
    "\n",
    "### 实际应用场景\n",
    "- **数据处理管道**：多进程解析文件 → 专用进程写入数据库\n",
    "- **深度学习训练**：DataLoader 加载数据 → 训练进程消费数据（PyTorch 内部机制）\n",
    "- **日志收集**：多服务产生日志 → 专用进程聚合写入文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
